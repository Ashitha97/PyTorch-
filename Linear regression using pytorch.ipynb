{Turkce 

 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the data , can have inputs and targets\n",
    "## let us take an example of our own and try doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input(temp,rainfall,humidity)\n",
    "inputs=np.array([[73,67,43],\n",
    "                [91,88,64],\n",
    "                [87,134,58],\n",
    "                [102,43,37],\n",
    "                [69,96,70]],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets (apples,oranges)\n",
    "targets=np.array([[56,70],\n",
    "                 [81,101],\n",
    "                 [119,133],\n",
    "                 [22,37],\n",
    "                 [103,119]],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#converting inputs and targets to pytorch tensors\n",
    "inputs=torch.from_numpy(inputs)\n",
    "targets=torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9308,  0.4709, -1.3459],\n",
      "        [ 0.2612,  0.6507,  0.1843]], requires_grad=True)\n",
      "tensor([ 0.1450, -0.3706], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#weights and biases\n",
    "w=torch.randn(2,3,requires_grad=True)\n",
    "b=torch.randn(2,requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model is a one that just perform matrix multiplications wrt the inputs and add biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- @ is a multiplication in pytorch\n",
    "- .t method returns transpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t()+b #@ is a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -94.1293,   70.2158],\n",
       "        [-129.2594,   92.4516],\n",
       "        [ -95.7991,  120.2325],\n",
       "        [-124.3494,   61.0678],\n",
       "        [-113.0896,   93.0170]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate predictions\n",
    "preds=model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a huge difference between the prediction with actual and predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18248.9863, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=(preds-targets)\n",
    "torch.sum(diff*diff)/diff.numel()\n",
    "#diff.numel gives number of elements in diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1,t2):\n",
    "    diff=t2-t1\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18248.9863, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#compute loss\n",
    "loss=mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from this we can see that each value differes from each target varibale by avg of 135 which is a pretty bad model and we need \n",
    "- improve it using gradient descent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.088808936936"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(18248.9863)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute gradients\n",
    "\n",
    "### computing the differential wrt the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9308,  0.4709, -1.3459],\n",
      "        [ 0.2612,  0.6507,  0.1843]], requires_grad=True)\n",
      "tensor([[-15723.6787, -16876.4395, -10582.3418],\n",
      "        [  -242.1672,   -781.6203,   -441.3271]])\n"
     ]
    }
   ],
   "source": [
    "#gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1450, -0.3706], requires_grad=True)\n",
      "tensor([-187.5254,   -4.6031])\n"
     ]
    }
   ],
   "source": [
    "#gradients for bias\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we need to reset the gradients back to zero because by calling zero_(), we need to do this because pytorch accumulates, gradients i.e the next time we call backward on loss the new gradient value keeps adding and which will result in unexpected results\n",
    "- as you can see the weights are the same only the gradients have gone away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9308,  0.4709, -1.3459],\n",
       "         [ 0.2612,  0.6507,  0.1843]], requires_grad=True),\n",
       " tensor([ 0.1450, -0.3706], requires_grad=True))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjust weights and biases\n",
    "\n",
    "## gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -94.1293,   70.2158],\n",
       "        [-129.2594,   92.4516],\n",
       "        [ -95.7991,  120.2325],\n",
       "        [-124.3494,   61.0678],\n",
       "        [-113.0896,   93.0170]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model(inputs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18248.9863, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the loss\n",
    "loss=mse(pred,targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-15723.6787, -16876.4395, -10582.3418],\n",
      "        [  -242.1672,   -781.6203,   -441.3271]])\n",
      "tensor([-187.5254,   -4.6031])\n"
     ]
    }
   ],
   "source": [
    "#compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally we update weigts and biases using gradients\n",
    "with torch.no_grad():\n",
    "    w -=w.grad* 1e-5\n",
    "    b -=b.grad* 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7736,  0.6397, -1.2401],\n",
      "        [ 0.2636,  0.6585,  0.1887]], requires_grad=True)\n",
      "tensor([ 0.1468, -0.3705], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#new weights\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12377.0312, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate loss again\n",
    "pred=model(inputs)\n",
    "loss=mse(pred,targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now again to reduce the loss we train the model for some number of epochs\n",
    "for i in range(10000):\n",
    "    pred=model(inputs)\n",
    "    loss=mse(pred,targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -=w.grad* 1e-5\n",
    "        b -=b.grad* 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5103, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate loss\n",
    "pred=model(inputs)\n",
    "loss=mse(pred,targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## as you can see the loss is reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.1920,  70.2467],\n",
       "        [ 82.1900, 100.7092],\n",
       "        [118.6890, 132.9687],\n",
       "        [ 21.0782,  37.0231],\n",
       "        [101.9245, 119.1278]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now the prediction is quite nearer to the target hence we can tell the model is quite good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
